{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookieFile = \"cookie.pkl\"\n",
    "cookies = None\n",
    "\n",
    "if os.path.exists(cookieFile):\n",
    "    with open(cookieFile, \"rb\") as inFile: cookies = pickle.load(inFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "if cookies is not None:\n",
    "    driver.get(\"https://weibo.com\")\n",
    "    for co in cookies: driver.add_cookie(co)\n",
    "driver.get(\"https://weibo.com\")\n",
    "# _ = input(\"press ENTER after login to weibo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跳转到搜索“腾讯”官方号\n",
    "driver.get(r\"https://s.weibo.com/user?q=%E8%85%BE%E8%AE%AF&auth=org_vip&page=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_element(driver, className, timeout=30):\n",
    "    try:\n",
    "        el = EC.presence_of_element_located((By.CLASS_NAME, className))\n",
    "        WebDriverWait(driver, timeout).until(el)\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout\")\n",
    "        return False\n",
    "    finally:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_search(driver, url, num_pages=5):\n",
    "    driver.get(url)\n",
    "    result = []\n",
    "    for i in range(num_pages):\n",
    "        page = []\n",
    "        if not wait_for_element(driver, \"name\"): break\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        for name in soup.select(\"div.info a.name\"):\n",
    "            page.append((name.get_text(), name[\"href\"]))\n",
    "        result.append(page)\n",
    "        try:\n",
    "            nextPageButton = driver.find_element_by_xpath('//a[text()=\"下一页\"]')\n",
    "            nextPageButton.click()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def collect_save(driver,searchData):\n",
    "    result = []\n",
    "    for page in searchData:\n",
    "        for element in page:\n",
    "            driver.get(\"https:\"+element[1])\n",
    "            if not wait_for_element(driver, \"PCD_counter\"): break\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            eleThree = soup.select(\"div#plc_main div.PCD_counter td.S_line1\")\n",
    "            assert len(eleThree) == 3 #确认搜到的是3个element\n",
    "            row = [\n",
    "                element[0], # 名字\n",
    "                \"https:\"+element[1], # url\n",
    "                int(eleThree[0].strong.string), # 关注数\n",
    "                int(eleThree[1].strong.string), # 粉丝数\n",
    "                int(eleThree[2].strong.string), # 微博数\n",
    "            ]\n",
    "            result.append(row)\n",
    "    result = pd.DataFrame(result,columns = [\"名字\",\"url\",\"关注数\",\"粉丝数\",\"微博数\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = collect_search(driver, r\"https://s.weibo.com/user?q=%E8%85%BE%E8%AE%AF&auth=org_vip&page=1\", num_pages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = collect_save(driver, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"sina.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://weibo.com\")\n",
    "with open(cookieFile, \"wb\") as outFile:\n",
    "    pickle.dump(driver.get_cookies(), outFile)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
